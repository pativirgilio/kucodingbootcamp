{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a Python script to perform a sentiment analysis of the Twitter activity of  __BBC, CBS, CNN, Fox, and New York times__.\n",
    "\n",
    "The first plot will be and/or feature the following:\n",
    "\n",
    "* Be a scatter plot of sentiments of the last __100__ tweets sent out by each news organization, ranging from -1.0 to 1.0, where a score of 0 expresses a neutral sentiment, -1 the most negative sentiment possible, and +1 the most positive sentiment possible.\n",
    "* Each plot point will reflect the _compound_ sentiment of a tweet.\n",
    "* Sort each plot point by its relative timestamp.\n",
    "\n",
    "The second plot will be a bar plot visualizing the _overall_ sentiments of the last 100 tweets from each organization. For this plot, you will again aggregate the compound sentiments analyzed by VADER.\n",
    "\n",
    "The tools of the trade you will need for your task as a data analyst include the following: tweepy, pandas, matplotlib, seaborn, textblob, and VADER.\n",
    "\n",
    "Your final Jupyter notebook must:\n",
    "\n",
    "* Pull last 100 tweets from each outlet.\n",
    "* Perform a sentiment analysis with the compound, positive, neutral, and negative scoring for each tweet.\n",
    "* Pull into a DataFrame the tweet's source acount, its text, its date, and its compound, positive, neutral, and negative sentiment scores.\n",
    "* Export the data in the DataFrame into a CSV file.\n",
    "* Save PNG images for each plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import tweepy\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from config import consumer_key, consumer_secret, access_token, access_token_secret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import and Initialize Sentiment Analyzer\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Twitter API Keys\n",
    "consumer_key = consumer_key\n",
    "consumer_secret = consumer_secret\n",
    "access_token = access_token\n",
    "access_token_secret = access_token_secret\n",
    "\n",
    "#Quetion to TOM: How to keep the API keys secret in GitHub????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Tweepy API Authentication\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth, parser=tweepy.parsers.JSONParser())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target Search Term\n",
    "target_term1 = \"@CNN\"\n",
    "target_term2 = \"@BBC\"\n",
    "target_term3 = \"@CBS\"\n",
    "target_term4 = \"@FOX\"\n",
    "target_term5 = \"@NYTIMES\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lists to hold sentiments\n",
    "NY = [] \n",
    "CNN = []\n",
    "BBC = []\n",
    "CBS = []\n",
    "FOX = []\n",
    "\n",
    "compound_listCNN = []\n",
    "positive_listCNN = []\n",
    "negative_listCNN = []\n",
    "neutral_listCNN = []\n",
    "\n",
    "compound_listBBC = []\n",
    "positive_listBBC = []\n",
    "negative_listBBC = []\n",
    "neutral_listBBC = []\n",
    "\n",
    "compound_listCBS = []\n",
    "positive_listCBS = []\n",
    "negative_listCBS = []\n",
    "neutral_listCBS = []\n",
    "\n",
    "compound_listFOX = []\n",
    "positive_listFOX = []\n",
    "negative_listFOX = []\n",
    "neutral_listFOX = []\n",
    "\n",
    "compound_listNYTIMES = []\n",
    "positive_listNYTIMES = []\n",
    "negative_listNYTIMES = []\n",
    "neutral_listNYTIMES = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab 100 tweets - CNN\n",
    "public_tweetsCNN = api.search(target_term1, count=100, result_type=\"recent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through all tweets\n",
    "for tweet in public_tweetsCNN[\"statuses\"]:\n",
    "\n",
    "    # Run Vader Analysis on each tweet\n",
    "    compound = analyzer.polarity_scores(tweet[\"text\"])[\"compound\"]\n",
    "    pos = analyzer.polarity_scores(tweet[\"text\"])[\"pos\"]\n",
    "    neu = analyzer.polarity_scores(tweet[\"text\"])[\"neu\"]\n",
    "    neg = analyzer.polarity_scores(tweet[\"text\"])[\"neg\"]\n",
    "\n",
    "    # Add each value to the appropriate array\n",
    "    compound_listCNN.append(compound)\n",
    "    positive_listCNN.append(pos)\n",
    "    negative_listCNN.append(neg)\n",
    "    neutral_listCNN.append(neu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the Average Sentiments\n",
    "sentimentCNN = {\"Date\": tweet[\"created_at\"],\n",
    "             \"Compound\": np.mean(compound_listCNN),\n",
    "             \"Positive\": np.mean(positive_listCNN),\n",
    "             \"Neutral\": np.mean(negative_listCNN),\n",
    "             \"Negative\": np.mean(neutral_listCNN)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Date': 'Wed Apr 25 03:31:39 +0000 2018', 'Compound': 0.11606200000000003, 'Positive': 0.09860999999999999, 'Neutral': 0.06801999999999998, 'Negative': 0.8334}\n"
     ]
    }
   ],
   "source": [
    "# Print the Sentiments\n",
    "print(sentimentCNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab 100 tweets - BBC\n",
    "public_tweetsBBC = api.search(target_term2, count=100, result_type=\"recent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through all tweets\n",
    "for tweet in public_tweetsBBC[\"statuses\"]:\n",
    "\n",
    "    # Run Vader Analysis on each tweet\n",
    "    compound = analyzer.polarity_scores(tweet[\"text\"])[\"compound\"]\n",
    "    pos = analyzer.polarity_scores(tweet[\"text\"])[\"pos\"]\n",
    "    neu = analyzer.polarity_scores(tweet[\"text\"])[\"neu\"]\n",
    "    neg = analyzer.polarity_scores(tweet[\"text\"])[\"neg\"]\n",
    "\n",
    "    # Add each value to the appropriate array\n",
    "    compound_listBBC.append(compound)\n",
    "    positive_listBBC.append(pos)\n",
    "    negative_listBBC.append(neg)\n",
    "    neutral_listBBC.append(neu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the Average Sentiments\n",
    "sentimentBBC = {\"Date\": tweet[\"created_at\"], \"Compound\": np.mean(compound_listBBC),\n",
    "             \"Positive\": np.mean(positive_listBBC),\n",
    "             \"Neutral\": np.mean(negative_listBBC),\n",
    "             \"Negative\": np.mean(neutral_listBBC)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Date': 'Wed Apr 25 02:53:00 +0000 2018', 'Compound': 0.21684318181818182, 'Positive': 0.10427272727272728, 'Neutral': 0.028170454545454547, 'Negative': 0.8675454545454545}\n"
     ]
    }
   ],
   "source": [
    "# Print the Sentiments\n",
    "print(sentimentBBC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Date': 'Wed Apr 25 02:38:59 +0000 2018', 'Compound': 0.137969, 'Positive': 0.08802000000000001, 'Neutral': 0.029190000000000004, 'Negative': 0.8828000000000001}\n"
     ]
    }
   ],
   "source": [
    "# Grab 100 tweets - CBS\n",
    "public_tweetsCBS = api.search(target_term3, count=100, result_type=\"recent\")\n",
    "\n",
    "for tweet in public_tweetsCBS[\"statuses\"]:\n",
    "\n",
    "# Run Vader Analysis on each tweet\n",
    "    compound = analyzer.polarity_scores(tweet[\"text\"])[\"compound\"]\n",
    "    pos = analyzer.polarity_scores(tweet[\"text\"])[\"pos\"]\n",
    "    neu = analyzer.polarity_scores(tweet[\"text\"])[\"neu\"]\n",
    "    neg = analyzer.polarity_scores(tweet[\"text\"])[\"neg\"]\n",
    "\n",
    "# Add each value to the appropriate array\n",
    "    compound_listCBS.append(compound)\n",
    "    positive_listCBS.append(pos)\n",
    "    negative_listCBS.append(neg)\n",
    "    neutral_listCBS.append(neu)\n",
    "\n",
    "    # Store the Average Sentiments\n",
    "sentimentCBS = {\"Date\": tweet[\"created_at\"], \n",
    "             \"Compound\": np.mean(compound_listCBS),\n",
    "             \"Positive\": np.mean(positive_listCBS),\n",
    "             \"Neutral\": np.mean(negative_listCBS),\n",
    "             \"Negative\": np.mean(neutral_listCBS)}\n",
    "# Print the Sentiments\n",
    "print(sentimentCBS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Date': 'Wed Apr 25 00:04:04 +0000 2018', 'Compound': 0.24671799999999997, 'Positive': 0.11324000000000005, 'Neutral': 0.0262, 'Negative': 0.8605699999999998}\n"
     ]
    }
   ],
   "source": [
    "# Grab 100 tweets - FOX\n",
    "public_tweetsFOX = api.search(target_term4, count=100, result_type=\"recent\")\n",
    "\n",
    "for tweet in public_tweetsFOX[\"statuses\"]:\n",
    "\n",
    "# Run Vader Analysis on each tweet\n",
    "    compound = analyzer.polarity_scores(tweet[\"text\"])[\"compound\"]\n",
    "    pos = analyzer.polarity_scores(tweet[\"text\"])[\"pos\"]\n",
    "    neu = analyzer.polarity_scores(tweet[\"text\"])[\"neu\"]\n",
    "    neg = analyzer.polarity_scores(tweet[\"text\"])[\"neg\"]\n",
    "\n",
    "# Add each value to the appropriate array\n",
    "    compound_listFOX.append(compound)\n",
    "    positive_listFOX.append(pos)\n",
    "    negative_listFOX.append(neg)\n",
    "    neutral_listFOX.append(neu)\n",
    "\n",
    "    # Store the Average Sentiments\n",
    "sentimentFOX = {\"Date\": tweet[\"created_at\"], \"Compound\": np.mean(compound_listFOX),\n",
    "             \"Positive\": np.mean(positive_listFOX),\n",
    "             \"Neutral\": np.mean(negative_listFOX),\n",
    "             \"Negative\": np.mean(neutral_listFOX)}\n",
    "# Print the Sentiments\n",
    "print(sentimentFOX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Date': 'Wed Apr 25 03:33:07 +0000 2018', 'Compound': 0.06038200000000002, 'Positive': 0.09031, 'Neutral': 0.08526, 'Negative': 0.8244500000000001}\n"
     ]
    }
   ],
   "source": [
    "# Grab 100 tweets - NYTIMES\n",
    "public_tweetsNYTIMES = api.search(target_term5, count=100, result_type=\"recent\")\n",
    "\n",
    "for tweet in public_tweetsNYTIMES[\"statuses\"]:\n",
    "\n",
    "# Run Vader Analysis on each tweet\n",
    "    compound = analyzer.polarity_scores(tweet[\"text\"])[\"compound\"]\n",
    "    pos = analyzer.polarity_scores(tweet[\"text\"])[\"pos\"]\n",
    "    neu = analyzer.polarity_scores(tweet[\"text\"])[\"neu\"]\n",
    "    neg = analyzer.polarity_scores(tweet[\"text\"])[\"neg\"]\n",
    "\n",
    "# Add each value to the appropriate array\n",
    "    compound_listNYTIMES.append(compound)\n",
    "    positive_listNYTIMES.append(pos)\n",
    "    negative_listNYTIMES.append(neg)\n",
    "    neutral_listNYTIMES.append(neu)\n",
    "\n",
    "    # Store the Average Sentiments\n",
    "sentimentNYTIMES = {\"Date\": tweet[\"created_at\"], \"Compound\": np.mean(compound_listNYTIMES),\n",
    "             \"Positive\": np.mean(positive_listNYTIMES),\n",
    "             \"Neutral\": np.mean(negative_listNYTIMES),\n",
    "             \"Negative\": np.mean(neutral_listNYTIMES)}\n",
    "# Print the Sentiments\n",
    "print(sentimentNYTIMES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add each sentiment@News to the all_results_list\n",
    "NY.append(sentimentNYTIMES)\n",
    "CNN.append(sentimentCNN)\n",
    "BBC.append(sentimentBBC)\n",
    "CBS.append(sentimentCBS)\n",
    "FOX.append(sentimentFOX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Compound': 0.06038200000000002,\n",
       "  'Date': 'Wed Apr 25 03:33:07 +0000 2018',\n",
       "  'Negative': 0.8244500000000001,\n",
       "  'Neutral': 0.08526,\n",
       "  'Positive': 0.09031}]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_sentiments = {\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PythonData]",
   "language": "python",
   "name": "conda-env-PythonData-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
